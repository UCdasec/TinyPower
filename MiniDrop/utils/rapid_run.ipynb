{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ed9ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:42:44.355452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mabon/Tiny_power/code/TinyPower/cnn/new_train.py:193: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:42:45.372758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-25 09:42:45.373265: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-25 09:42:45.373708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-07-25 09:42:45.427442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.427902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-07-25 09:42:45.427915: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-25 09:42:45.428774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-25 09:42:45.428793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-25 09:42:45.429637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-25 09:42:45.429763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-25 09:42:45.430661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-25 09:42:45.431137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-25 09:42:45.432976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-25 09:42:45.433033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.433500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.433928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-25 09:42:45.433947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-25 09:42:45.870164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-25 09:42:45.870183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-25 09:42:45.870187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-25 09:42:45.870303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.870819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.871250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:45.871669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 22454 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the self-defined attack window\n",
      "training with 50000 traces\n",
      "trace data shape is:  (50000, 1000)\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.37, 0.74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:42:47.115448: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-25 09:42:47.115589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.116031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-07-25 09:42:47.116052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-25 09:42:47.116068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-25 09:42:47.116076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-25 09:42:47.116084: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-25 09:42:47.116091: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-25 09:42:47.116099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-25 09:42:47.116107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-25 09:42:47.116115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-25 09:42:47.116149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.116575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.116979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-25 09:42:47.117070: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-25 09:42:47.117109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.117518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-07-25 09:42:47.117528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-25 09:42:47.117536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-25 09:42:47.117544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-25 09:42:47.117551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-25 09:42:47.117558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-25 09:42:47.117566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-25 09:42:47.117573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-25 09:42:47.117581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-25 09:42:47.117606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.118032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.118471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-25 09:42:47.118489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-25 09:42:47.118492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-25 09:42:47.118494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-25 09:42:47.118536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.118963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 09:42:47.119371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22454 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[log] --- finish construct the cnn2 model\n",
      "ORiginal Model\n",
      "Model: \"cnn_best\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 500, 64)           768       \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 250, 128)          90240     \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling1 (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 125, 256)          360704    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling1 (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 62, 512)           1442304   \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling1 (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 31, 512)           2884096   \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "block_flatten (Flatten)      (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "block_fc1 (Dense)            (None, 4096)              31461376  \n",
      "_________________________________________________________________\n",
      "block_fc2 (Dense)            (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 36873     \n",
      "=================================================================\n",
      "Total params: 53,057,673\n",
      "Trainable params: 53,057,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned Model\n",
      "Model: \"cnn_best\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 500, 64)           768       \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 250, 128)          90240     \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling1 (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 125, 256)          360704    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling1 (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 62, 512)           1442304   \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling1 (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 31, 512)           2884096   \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1515)              11636715  \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 3031)              4594996   \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 9)                 27288     \n",
      "=================================================================\n",
      "Total params: 21,037,111\n",
      "Trainable params: 21,037,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "now train dnn model for HW leakage model over /home/mabon/Tiny_power/datasets/em/xmega/X1_K1_150k_L11.npz dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:42:47.813153: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-07-25 09:42:47.813171: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-07-25 09:42:47.813186: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2023-07-25 09:42:47.813562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2023-07-25 09:42:47.913845: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2023-07-25 09:42:47.913947: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2023-07-25 09:42:48.007988: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-07-25 09:42:48.026513: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 09:42:48.516768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-25 09:42:48.632785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-25 09:42:49.169843: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2023-07-25 09:42:49.198716: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 13s 20ms/step - loss: 1.8212 - accuracy: 0.2738 - val_loss: 1.7581 - val_accuracy: 0.2656\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.26560, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 2/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.7591 - accuracy: 0.2721 - val_loss: 1.7443 - val_accuracy: 0.2908\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.26560 to 0.29080, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 3/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.7257 - accuracy: 0.2909 - val_loss: 1.6498 - val_accuracy: 0.3582\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.29080 to 0.35820, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 4/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.5928 - accuracy: 0.3560 - val_loss: 1.4739 - val_accuracy: 0.3954\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.35820 to 0.39540, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 5/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.4419 - accuracy: 0.3954 - val_loss: 1.3805 - val_accuracy: 0.4182\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.39540 to 0.41820, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 6/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.3581 - accuracy: 0.4279 - val_loss: 1.3465 - val_accuracy: 0.4120\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.41820\n",
      "Epoch 7/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.3209 - accuracy: 0.4332 - val_loss: 1.3204 - val_accuracy: 0.4304\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.41820 to 0.43040, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 8/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.2994 - accuracy: 0.4426 - val_loss: 1.3119 - val_accuracy: 0.4350\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.43040 to 0.43500, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 9/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.2900 - accuracy: 0.4404 - val_loss: 1.2943 - val_accuracy: 0.4406\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.43500 to 0.44060, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 10/150\n",
      "450/450 [==============================] - 9s 19ms/step - loss: 1.2698 - accuracy: 0.4530 - val_loss: 1.2768 - val_accuracy: 0.4494\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.44060 to 0.44940, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 11/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2679 - accuracy: 0.4503 - val_loss: 1.2711 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.44940\n",
      "Epoch 12/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2602 - accuracy: 0.4504 - val_loss: 1.2819 - val_accuracy: 0.4484\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.44940\n",
      "Epoch 13/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2568 - accuracy: 0.4556 - val_loss: 1.2769 - val_accuracy: 0.4446\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.44940\n",
      "Epoch 14/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2561 - accuracy: 0.4557 - val_loss: 1.2528 - val_accuracy: 0.4562\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.44940 to 0.45620, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 15/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2404 - accuracy: 0.4606 - val_loss: 1.2554 - val_accuracy: 0.4452\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.45620\n",
      "Epoch 16/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2427 - accuracy: 0.4608 - val_loss: 1.2542 - val_accuracy: 0.4530\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.45620\n",
      "Epoch 17/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2427 - accuracy: 0.4577 - val_loss: 1.2589 - val_accuracy: 0.4534\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.45620\n",
      "Epoch 18/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2228 - accuracy: 0.4674 - val_loss: 1.2636 - val_accuracy: 0.4528\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.45620\n",
      "Epoch 19/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2295 - accuracy: 0.4652 - val_loss: 1.2532 - val_accuracy: 0.4566\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.45620 to 0.45660, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 20/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2289 - accuracy: 0.4669 - val_loss: 1.2412 - val_accuracy: 0.4574\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.45660 to 0.45740, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 21/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2283 - accuracy: 0.4704 - val_loss: 1.2399 - val_accuracy: 0.4576\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.45740 to 0.45760, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 22/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2181 - accuracy: 0.4721 - val_loss: 1.2481 - val_accuracy: 0.4596\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.45760 to 0.45960, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 23/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2129 - accuracy: 0.4735 - val_loss: 1.2345 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.45960 to 0.46380, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 24/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2214 - accuracy: 0.4699 - val_loss: 1.2313 - val_accuracy: 0.4636\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.46380\n",
      "Epoch 25/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2135 - accuracy: 0.4707 - val_loss: 1.2405 - val_accuracy: 0.4604\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.46380\n",
      "Epoch 26/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2075 - accuracy: 0.4711 - val_loss: 1.2249 - val_accuracy: 0.4676\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.46380 to 0.46760, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 27/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2182 - accuracy: 0.4716 - val_loss: 1.2279 - val_accuracy: 0.4620\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.46760\n",
      "Epoch 28/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1997 - accuracy: 0.4772 - val_loss: 1.2293 - val_accuracy: 0.4670\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.46760\n",
      "Epoch 29/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2101 - accuracy: 0.4712 - val_loss: 1.2202 - val_accuracy: 0.4662\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.46760\n",
      "Epoch 30/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2098 - accuracy: 0.4764 - val_loss: 1.2260 - val_accuracy: 0.4654\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.46760\n",
      "Epoch 31/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2057 - accuracy: 0.4767 - val_loss: 1.2198 - val_accuracy: 0.4686\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.46760 to 0.46860, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2040 - accuracy: 0.4788 - val_loss: 1.2149 - val_accuracy: 0.4708\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.46860 to 0.47080, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 33/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.2028 - accuracy: 0.4785 - val_loss: 1.2140 - val_accuracy: 0.4794\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.47080 to 0.47940, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 34/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1991 - accuracy: 0.4796 - val_loss: 1.2196 - val_accuracy: 0.4716\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.47940\n",
      "Epoch 35/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1973 - accuracy: 0.4827 - val_loss: 1.2221 - val_accuracy: 0.4696\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.47940\n",
      "Epoch 36/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1902 - accuracy: 0.4841 - val_loss: 1.2265 - val_accuracy: 0.4716\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.47940\n",
      "Epoch 37/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1940 - accuracy: 0.4830 - val_loss: 1.2378 - val_accuracy: 0.4668\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.47940\n",
      "Epoch 38/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1925 - accuracy: 0.4878 - val_loss: 1.2121 - val_accuracy: 0.4782\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.47940\n",
      "Epoch 39/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1850 - accuracy: 0.4869 - val_loss: 1.2149 - val_accuracy: 0.4754\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.47940\n",
      "Epoch 40/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1868 - accuracy: 0.4832 - val_loss: 1.2305 - val_accuracy: 0.4670\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.47940\n",
      "Epoch 41/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1867 - accuracy: 0.4833 - val_loss: 1.2069 - val_accuracy: 0.4824\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.47940 to 0.48240, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 42/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1777 - accuracy: 0.4898 - val_loss: 1.2030 - val_accuracy: 0.4844\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.48240 to 0.48440, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 43/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1821 - accuracy: 0.4868 - val_loss: 1.2073 - val_accuracy: 0.4790\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.48440\n",
      "Epoch 44/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1787 - accuracy: 0.4888 - val_loss: 1.2023 - val_accuracy: 0.4832\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.48440\n",
      "Epoch 45/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1712 - accuracy: 0.4931 - val_loss: 1.2271 - val_accuracy: 0.4752\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.48440\n",
      "Epoch 46/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1721 - accuracy: 0.4901 - val_loss: 1.1997 - val_accuracy: 0.4840\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.48440\n",
      "Epoch 47/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1724 - accuracy: 0.4909 - val_loss: 1.2027 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.48440\n",
      "Epoch 48/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1751 - accuracy: 0.4888 - val_loss: 1.1945 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.48440 to 0.48500, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 49/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1665 - accuracy: 0.4969 - val_loss: 1.2165 - val_accuracy: 0.4716\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.48500\n",
      "Epoch 50/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1622 - accuracy: 0.4985 - val_loss: 1.2462 - val_accuracy: 0.4700\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.48500\n",
      "Epoch 51/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1618 - accuracy: 0.4939 - val_loss: 1.1990 - val_accuracy: 0.4842\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.48500\n",
      "Epoch 52/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1555 - accuracy: 0.5035 - val_loss: 1.2144 - val_accuracy: 0.4808\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.48500\n",
      "Epoch 53/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1587 - accuracy: 0.4999 - val_loss: 1.1943 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.48500\n",
      "Epoch 54/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1565 - accuracy: 0.4995 - val_loss: 1.1893 - val_accuracy: 0.4898\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.48500 to 0.48980, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 55/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1540 - accuracy: 0.5017 - val_loss: 1.1829 - val_accuracy: 0.4904\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.48980 to 0.49040, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 56/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1523 - accuracy: 0.5008 - val_loss: 1.1833 - val_accuracy: 0.4866\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.49040\n",
      "Epoch 57/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1481 - accuracy: 0.5004 - val_loss: 1.1846 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.49040\n",
      "Epoch 58/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1480 - accuracy: 0.5025 - val_loss: 1.1935 - val_accuracy: 0.4794\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.49040\n",
      "Epoch 59/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1471 - accuracy: 0.5037 - val_loss: 1.1798 - val_accuracy: 0.4912\n",
      "\n",
      "Epoch 00059: val_accuracy improved from 0.49040 to 0.49120, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 60/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1442 - accuracy: 0.5031 - val_loss: 1.1753 - val_accuracy: 0.4930\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.49120 to 0.49300, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 61/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1374 - accuracy: 0.5082 - val_loss: 1.1789 - val_accuracy: 0.4884\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.49300\n",
      "Epoch 62/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1424 - accuracy: 0.5048 - val_loss: 1.1963 - val_accuracy: 0.4820\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.49300\n",
      "Epoch 63/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1401 - accuracy: 0.5097 - val_loss: 1.1783 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.49300\n",
      "Epoch 64/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1345 - accuracy: 0.5089 - val_loss: 1.1707 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.49300\n",
      "Epoch 65/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1358 - accuracy: 0.5120 - val_loss: 1.1692 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.49300\n",
      "Epoch 66/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1258 - accuracy: 0.5159 - val_loss: 1.1741 - val_accuracy: 0.4872\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.49300\n",
      "Epoch 67/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1347 - accuracy: 0.5136 - val_loss: 1.1657 - val_accuracy: 0.4918\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.49300\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1299 - accuracy: 0.5122 - val_loss: 1.1678 - val_accuracy: 0.4892\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.49300\n",
      "Epoch 69/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1281 - accuracy: 0.5135 - val_loss: 1.1668 - val_accuracy: 0.4914\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.49300\n",
      "Epoch 70/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1246 - accuracy: 0.5160 - val_loss: 1.1762 - val_accuracy: 0.4906\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.49300\n",
      "Epoch 71/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1204 - accuracy: 0.5177 - val_loss: 1.1935 - val_accuracy: 0.4858\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.49300\n",
      "Epoch 72/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1228 - accuracy: 0.5184 - val_loss: 1.1665 - val_accuracy: 0.4944\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.49300 to 0.49440, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 73/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1245 - accuracy: 0.5190 - val_loss: 1.1717 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.49440\n",
      "Epoch 74/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1204 - accuracy: 0.5184 - val_loss: 1.1601 - val_accuracy: 0.4958\n",
      "\n",
      "Epoch 00074: val_accuracy improved from 0.49440 to 0.49580, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 75/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1149 - accuracy: 0.5211 - val_loss: 1.1745 - val_accuracy: 0.4942\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.49580\n",
      "Epoch 76/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1185 - accuracy: 0.5222 - val_loss: 1.2055 - val_accuracy: 0.4796\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.49580\n",
      "Epoch 77/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1221 - accuracy: 0.5170 - val_loss: 1.1581 - val_accuracy: 0.4956\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.49580\n",
      "Epoch 78/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1104 - accuracy: 0.5270 - val_loss: 1.1567 - val_accuracy: 0.4984\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.49580 to 0.49840, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 79/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1166 - accuracy: 0.5273 - val_loss: 1.1546 - val_accuracy: 0.4950\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.49840\n",
      "Epoch 80/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1085 - accuracy: 0.5229 - val_loss: 1.1541 - val_accuracy: 0.4988\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.49840 to 0.49880, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 81/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1103 - accuracy: 0.5220 - val_loss: 1.1525 - val_accuracy: 0.5056\n",
      "\n",
      "Epoch 00081: val_accuracy improved from 0.49880 to 0.50560, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 82/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1082 - accuracy: 0.5259 - val_loss: 1.1499 - val_accuracy: 0.4994\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.50560\n",
      "Epoch 83/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1049 - accuracy: 0.5264 - val_loss: 1.1576 - val_accuracy: 0.4982\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.50560\n",
      "Epoch 84/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1062 - accuracy: 0.5236 - val_loss: 1.2089 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.50560\n",
      "Epoch 85/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1032 - accuracy: 0.5275 - val_loss: 1.1655 - val_accuracy: 0.4910\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.50560\n",
      "Epoch 86/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1086 - accuracy: 0.5264 - val_loss: 1.1605 - val_accuracy: 0.4982\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.50560\n",
      "Epoch 87/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0973 - accuracy: 0.5326 - val_loss: 1.1775 - val_accuracy: 0.4902\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.50560\n",
      "Epoch 88/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1016 - accuracy: 0.5279 - val_loss: 1.1872 - val_accuracy: 0.4894\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.50560\n",
      "Epoch 89/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0967 - accuracy: 0.5308 - val_loss: 1.1501 - val_accuracy: 0.4992\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.50560\n",
      "Epoch 90/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0904 - accuracy: 0.5276 - val_loss: 1.1533 - val_accuracy: 0.5014\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.50560\n",
      "Epoch 91/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.1040 - accuracy: 0.5272 - val_loss: 1.1604 - val_accuracy: 0.5034\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.50560\n",
      "Epoch 92/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0916 - accuracy: 0.5343 - val_loss: 1.1474 - val_accuracy: 0.5058\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.50560 to 0.50580, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 93/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0930 - accuracy: 0.5294 - val_loss: 1.1470 - val_accuracy: 0.5038\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.50580\n",
      "Epoch 94/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0894 - accuracy: 0.5348 - val_loss: 1.1442 - val_accuracy: 0.5052\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.50580\n",
      "Epoch 95/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0936 - accuracy: 0.5319 - val_loss: 1.1352 - val_accuracy: 0.5060\n",
      "\n",
      "Epoch 00095: val_accuracy improved from 0.50580 to 0.50600, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 96/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0888 - accuracy: 0.5369 - val_loss: 1.1414 - val_accuracy: 0.5078\n",
      "\n",
      "Epoch 00096: val_accuracy improved from 0.50600 to 0.50780, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 97/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0791 - accuracy: 0.5411 - val_loss: 1.1486 - val_accuracy: 0.4992\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.50780\n",
      "Epoch 98/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0864 - accuracy: 0.5365 - val_loss: 1.1554 - val_accuracy: 0.5034\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.50780\n",
      "Epoch 99/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0793 - accuracy: 0.5408 - val_loss: 1.1975 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.50780\n",
      "Epoch 100/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0856 - accuracy: 0.5375 - val_loss: 1.1487 - val_accuracy: 0.5016\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.50780\n",
      "Epoch 101/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0831 - accuracy: 0.5405 - val_loss: 1.1772 - val_accuracy: 0.4954\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.50780\n",
      "Epoch 102/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0830 - accuracy: 0.5392 - val_loss: 1.1354 - val_accuracy: 0.5074\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.50780\n",
      "Epoch 103/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0765 - accuracy: 0.5375 - val_loss: 1.1559 - val_accuracy: 0.5038\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.50780\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0741 - accuracy: 0.5403 - val_loss: 1.1474 - val_accuracy: 0.5044\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.50780\n",
      "Epoch 105/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0706 - accuracy: 0.5400 - val_loss: 1.1363 - val_accuracy: 0.5084\n",
      "\n",
      "Epoch 00105: val_accuracy improved from 0.50780 to 0.50840, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 106/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0748 - accuracy: 0.5412 - val_loss: 1.1381 - val_accuracy: 0.5062\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.50840\n",
      "Epoch 107/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0649 - accuracy: 0.5447 - val_loss: 1.1328 - val_accuracy: 0.5080\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.50840\n",
      "Epoch 108/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0742 - accuracy: 0.5404 - val_loss: 1.1334 - val_accuracy: 0.5068\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.50840\n",
      "Epoch 109/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0761 - accuracy: 0.5390 - val_loss: 1.1318 - val_accuracy: 0.5056\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.50840\n",
      "Epoch 110/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0694 - accuracy: 0.5427 - val_loss: 1.1456 - val_accuracy: 0.5070\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.50840\n",
      "Epoch 111/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0663 - accuracy: 0.5425 - val_loss: 1.1549 - val_accuracy: 0.5096\n",
      "\n",
      "Epoch 00111: val_accuracy improved from 0.50840 to 0.50960, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 112/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0614 - accuracy: 0.5461 - val_loss: 1.1327 - val_accuracy: 0.5088\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.50960\n",
      "Epoch 113/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0728 - accuracy: 0.5421 - val_loss: 1.1443 - val_accuracy: 0.5030\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.50960\n",
      "Epoch 114/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0642 - accuracy: 0.5459 - val_loss: 1.1339 - val_accuracy: 0.5108\n",
      "\n",
      "Epoch 00114: val_accuracy improved from 0.50960 to 0.51080, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 115/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0581 - accuracy: 0.5493 - val_loss: 1.1442 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.51080\n",
      "Epoch 116/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0567 - accuracy: 0.5486 - val_loss: 1.1235 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.51080\n",
      "Epoch 117/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0566 - accuracy: 0.5498 - val_loss: 1.1393 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.51080\n",
      "Epoch 118/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0589 - accuracy: 0.5461 - val_loss: 1.1737 - val_accuracy: 0.5028\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.51080\n",
      "Epoch 119/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0576 - accuracy: 0.5483 - val_loss: 1.1703 - val_accuracy: 0.4992\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.51080\n",
      "Epoch 120/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0538 - accuracy: 0.5506 - val_loss: 1.1321 - val_accuracy: 0.5150\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.51080 to 0.51500, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 121/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0569 - accuracy: 0.5486 - val_loss: 1.1471 - val_accuracy: 0.5084\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.51500\n",
      "Epoch 122/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0563 - accuracy: 0.5521 - val_loss: 1.1651 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.51500\n",
      "Epoch 123/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0504 - accuracy: 0.5492 - val_loss: 1.1227 - val_accuracy: 0.5110\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.51500\n",
      "Epoch 124/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0486 - accuracy: 0.5537 - val_loss: 1.1337 - val_accuracy: 0.5130\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.51500\n",
      "Epoch 125/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0472 - accuracy: 0.5501 - val_loss: 1.1378 - val_accuracy: 0.5130\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.51500\n",
      "Epoch 126/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0494 - accuracy: 0.5505 - val_loss: 1.1312 - val_accuracy: 0.5142\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.51500\n",
      "Epoch 127/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0451 - accuracy: 0.5528 - val_loss: 1.1272 - val_accuracy: 0.5122\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.51500\n",
      "Epoch 128/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0511 - accuracy: 0.5525 - val_loss: 1.1281 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00128: val_accuracy improved from 0.51500 to 0.51560, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 129/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0477 - accuracy: 0.5533 - val_loss: 1.1214 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.51560\n",
      "Epoch 130/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0415 - accuracy: 0.5571 - val_loss: 1.1368 - val_accuracy: 0.5152\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.51560\n",
      "Epoch 131/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0423 - accuracy: 0.5562 - val_loss: 1.1687 - val_accuracy: 0.5036\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.51560\n",
      "Epoch 132/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0377 - accuracy: 0.5604 - val_loss: 1.1260 - val_accuracy: 0.5140\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.51560\n",
      "Epoch 133/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0356 - accuracy: 0.5596 - val_loss: 1.1570 - val_accuracy: 0.5078\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.51560\n",
      "Epoch 134/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0363 - accuracy: 0.5571 - val_loss: 1.1252 - val_accuracy: 0.5144\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.51560\n",
      "Epoch 135/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0323 - accuracy: 0.5590 - val_loss: 1.1145 - val_accuracy: 0.5182\n",
      "\n",
      "Epoch 00135: val_accuracy improved from 0.51560 to 0.51820, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 136/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0344 - accuracy: 0.5567 - val_loss: 1.1434 - val_accuracy: 0.5120\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.51820\n",
      "Epoch 137/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0418 - accuracy: 0.5563 - val_loss: 1.1250 - val_accuracy: 0.5124\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.51820\n",
      "Epoch 138/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0364 - accuracy: 0.5571 - val_loss: 1.1409 - val_accuracy: 0.5154\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.51820\n",
      "Epoch 139/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0341 - accuracy: 0.5605 - val_loss: 1.1207 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00139: val_accuracy improved from 0.51820 to 0.52300, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 140/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0289 - accuracy: 0.5634 - val_loss: 1.1147 - val_accuracy: 0.5196\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.52300\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0320 - accuracy: 0.5581 - val_loss: 1.1148 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.52300\n",
      "Epoch 142/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0331 - accuracy: 0.5624 - val_loss: 1.1446 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.52300\n",
      "Epoch 143/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0297 - accuracy: 0.5587 - val_loss: 1.1481 - val_accuracy: 0.5148\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.52300\n",
      "Epoch 144/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0241 - accuracy: 0.5626 - val_loss: 1.1265 - val_accuracy: 0.5148\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.52300\n",
      "Epoch 145/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0308 - accuracy: 0.5628 - val_loss: 1.1249 - val_accuracy: 0.5178\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.52300\n",
      "Epoch 146/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0224 - accuracy: 0.5632 - val_loss: 1.1304 - val_accuracy: 0.5152\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.52300\n",
      "Epoch 147/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0157 - accuracy: 0.5707 - val_loss: 1.1217 - val_accuracy: 0.5236\n",
      "\n",
      "Epoch 00147: val_accuracy improved from 0.52300 to 0.52360, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "Epoch 148/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0203 - accuracy: 0.5689 - val_loss: 1.1195 - val_accuracy: 0.5236\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.52360\n",
      "Epoch 149/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0187 - accuracy: 0.5662 - val_loss: 1.1357 - val_accuracy: 0.5132\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.52360\n",
      "Epoch 150/150\n",
      "450/450 [==============================] - 9s 20ms/step - loss: 1.0120 - accuracy: 0.5714 - val_loss: 1.1221 - val_accuracy: 0.5208\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.52360\n",
      "[LOG] -- model save to path: /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/model/best_model.h5\n",
      "RUNTIME:  1415.2401485443115\n",
      "TIME PER EPOCH 9.434934323628744\n"
     ]
    }
   ],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/em/xmega/X1_K1_150k_L11.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_EM_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1_EM/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h256/ -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1_EM/fpgm/custum/N256/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddad396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the self-defined attack window\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 10:06:23.066012: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-07-25 10:06:23.066120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 10:06:23.066339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: TITAN RTX computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-07-25 10:06:23.066363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-07-25 10:06:23.066417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-07-25 10:06:23.066428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-07-25 10:06:23.066437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-07-25 10:06:23.066446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-07-25 10:06:23.066454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-07-25 10:06:23.066463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-07-25 10:06:23.066472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-07-25 10:06:23.066507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 10:06:23.066711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 10:06:23.066888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-07-25 10:06:23.066905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-07-25 10:06:23.066908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-07-25 10:06:23.066910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-07-25 10:06:23.066954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 10:06:23.067158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-25 10:06:23.067340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 22454 MB memory) -> physical GPU (device: 0, name: TITAN RTX, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 50000 traces\n",
      "trace data shape is:  (50000, 1000)\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.83]\n",
      "[log] --- finish construct the cnn2 model\n",
      "ORiginal Model\n",
      "Model: \"cnn_best\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 500, 64)           768       \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 250, 128)          90240     \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling1 (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 125, 256)          360704    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling1 (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 62, 512)           1442304   \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling1 (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 31, 512)           2884096   \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "block_flatten (Flatten)      (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "block_fc1 (Dense)            (None, 4096)              31461376  \n",
      "_________________________________________________________________\n",
      "block_fc2 (Dense)            (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 36873     \n",
      "=================================================================\n",
      "Total params: 53,057,673\n",
      "Trainable params: 53,057,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pruned Model\n",
      "Model: \"cnn_best\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1000, 1)]         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv1D)        (None, 500, 64)           768       \n",
      "_________________________________________________________________\n",
      "block1_pool (AveragePooling1 (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv1D)        (None, 250, 128)          90240     \n",
      "_________________________________________________________________\n",
      "block2_pool (AveragePooling1 (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv1D)        (None, 125, 256)          360704    \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling1 (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv1D)        (None, 62, 512)           1442304   \n",
      "_________________________________________________________________\n",
      "block4_pool (AveragePooling1 (None, 31, 512)           0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv1D)        (None, 31, 512)           2884096   \n",
      "_________________________________________________________________\n",
      "block5_pool (AveragePooling1 (None, 15, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 3891)              29886771  \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 3399)              13228908  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 9)                 30600     \n",
      "=================================================================\n",
      "Total params: 47,924,391\n",
      "Trainable params: 47,924,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "now train dnn model for HW leakage model over /home/mabon/Tiny_power/datasets/em/xmega/X1_K1_150k_L11.npz dataset...\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 10:06:24.841166: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-07-25 10:06:24.841186: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-07-25 10:06:24.841578: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n",
      "2023-07-25 10:06:24.841592: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 12s 26ms/step - loss: 1.8062 - accuracy: 0.2689 - val_loss: 1.7461 - val_accuracy: 0.3208\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32080, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 2/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.7114 - accuracy: 0.2994 - val_loss: 1.5796 - val_accuracy: 0.3430\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.32080 to 0.34300, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 3/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.5081 - accuracy: 0.3831 - val_loss: 1.3919 - val_accuracy: 0.4190\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.34300 to 0.41900, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 4/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.3680 - accuracy: 0.4248 - val_loss: 1.3317 - val_accuracy: 0.4314\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.41900 to 0.43140, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 5/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.3139 - accuracy: 0.4375 - val_loss: 1.2990 - val_accuracy: 0.4414\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.43140 to 0.44140, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 6/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2844 - accuracy: 0.4476 - val_loss: 1.3326 - val_accuracy: 0.4194\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.44140\n",
      "Epoch 7/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2603 - accuracy: 0.4554 - val_loss: 1.2740 - val_accuracy: 0.4484\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.44140 to 0.44840, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 8/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2531 - accuracy: 0.4581 - val_loss: 1.2869 - val_accuracy: 0.4502\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.44840 to 0.45020, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 9/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2444 - accuracy: 0.4621 - val_loss: 1.2570 - val_accuracy: 0.4512\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.45020 to 0.45120, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 10/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2414 - accuracy: 0.4625 - val_loss: 1.2967 - val_accuracy: 0.4358\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.45120\n",
      "Epoch 11/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2314 - accuracy: 0.4654 - val_loss: 1.2595 - val_accuracy: 0.4546\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.45120 to 0.45460, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 12/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2353 - accuracy: 0.4624 - val_loss: 1.2389 - val_accuracy: 0.4672\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.45460 to 0.46720, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 13/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2231 - accuracy: 0.4703 - val_loss: 1.2904 - val_accuracy: 0.4440\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.46720\n",
      "Epoch 14/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2228 - accuracy: 0.4715 - val_loss: 1.2660 - val_accuracy: 0.4546\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.46720\n",
      "Epoch 15/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2151 - accuracy: 0.4713 - val_loss: 1.2279 - val_accuracy: 0.4686\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.46720 to 0.46860, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 16/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2083 - accuracy: 0.4753 - val_loss: 1.2310 - val_accuracy: 0.4690\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.46860 to 0.46900, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 17/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2039 - accuracy: 0.4775 - val_loss: 1.2294 - val_accuracy: 0.4708\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.46900 to 0.47080, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 18/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1993 - accuracy: 0.4753 - val_loss: 1.2335 - val_accuracy: 0.4642\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.47080\n",
      "Epoch 19/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.2019 - accuracy: 0.4805 - val_loss: 1.2440 - val_accuracy: 0.4614\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.47080\n",
      "Epoch 20/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1991 - accuracy: 0.4816 - val_loss: 1.2237 - val_accuracy: 0.4760\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.47080 to 0.47600, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 21/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1944 - accuracy: 0.4850 - val_loss: 1.2209 - val_accuracy: 0.4756\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.47600\n",
      "Epoch 22/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1866 - accuracy: 0.4839 - val_loss: 1.2426 - val_accuracy: 0.4660\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.47600\n",
      "Epoch 23/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1856 - accuracy: 0.4838 - val_loss: 1.2057 - val_accuracy: 0.4818\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.47600 to 0.48180, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 24/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1900 - accuracy: 0.4816 - val_loss: 1.2107 - val_accuracy: 0.4766\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.48180\n",
      "Epoch 25/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1766 - accuracy: 0.4922 - val_loss: 1.2063 - val_accuracy: 0.4816\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.48180\n",
      "Epoch 26/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1755 - accuracy: 0.4926 - val_loss: 1.1988 - val_accuracy: 0.4828\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.48180 to 0.48280, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 27/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1708 - accuracy: 0.4942 - val_loss: 1.2023 - val_accuracy: 0.4822\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.48280\n",
      "Epoch 28/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1710 - accuracy: 0.4920 - val_loss: 1.2082 - val_accuracy: 0.4790\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.48280\n",
      "Epoch 29/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1668 - accuracy: 0.4961 - val_loss: 1.1898 - val_accuracy: 0.4880\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.48280 to 0.48800, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 30/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1596 - accuracy: 0.4990 - val_loss: 1.2070 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.48800\n",
      "Epoch 31/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1641 - accuracy: 0.5006 - val_loss: 1.1944 - val_accuracy: 0.4830\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.48800\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1552 - accuracy: 0.5028 - val_loss: 1.1848 - val_accuracy: 0.4888\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.48800 to 0.48880, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 33/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1535 - accuracy: 0.5009 - val_loss: 1.1769 - val_accuracy: 0.4926\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.48880 to 0.49260, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 34/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1542 - accuracy: 0.5020 - val_loss: 1.1817 - val_accuracy: 0.4872\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.49260\n",
      "Epoch 35/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1498 - accuracy: 0.5042 - val_loss: 1.2160 - val_accuracy: 0.4804\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.49260\n",
      "Epoch 36/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1487 - accuracy: 0.5027 - val_loss: 1.1763 - val_accuracy: 0.4934\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.49260 to 0.49340, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 37/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1515 - accuracy: 0.5041 - val_loss: 1.1779 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.49340\n",
      "Epoch 38/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1461 - accuracy: 0.5043 - val_loss: 1.1780 - val_accuracy: 0.4896\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.49340\n",
      "Epoch 39/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1377 - accuracy: 0.5091 - val_loss: 1.1627 - val_accuracy: 0.4954\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.49340 to 0.49540, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 40/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1388 - accuracy: 0.5070 - val_loss: 1.1770 - val_accuracy: 0.4922\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.49540\n",
      "Epoch 41/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1356 - accuracy: 0.5091 - val_loss: 1.1699 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.49540 to 0.49760, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 42/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1324 - accuracy: 0.5139 - val_loss: 1.1659 - val_accuracy: 0.4974\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.49760\n",
      "Epoch 43/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1303 - accuracy: 0.5130 - val_loss: 1.1706 - val_accuracy: 0.4914\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.49760\n",
      "Epoch 44/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1277 - accuracy: 0.5158 - val_loss: 1.1681 - val_accuracy: 0.5010\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.49760 to 0.50100, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 45/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1266 - accuracy: 0.5194 - val_loss: 1.1668 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.50100\n",
      "Epoch 46/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1239 - accuracy: 0.5188 - val_loss: 1.1617 - val_accuracy: 0.4966\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.50100\n",
      "Epoch 47/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1292 - accuracy: 0.5174 - val_loss: 1.1594 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.50100\n",
      "Epoch 48/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1146 - accuracy: 0.5210 - val_loss: 1.1611 - val_accuracy: 0.5022\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.50100 to 0.50220, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 49/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1194 - accuracy: 0.5210 - val_loss: 1.2113 - val_accuracy: 0.4870\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.50220\n",
      "Epoch 50/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1156 - accuracy: 0.5216 - val_loss: 1.1716 - val_accuracy: 0.4936\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.50220\n",
      "Epoch 51/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1125 - accuracy: 0.5180 - val_loss: 1.1591 - val_accuracy: 0.4980\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.50220\n",
      "Epoch 52/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1115 - accuracy: 0.5211 - val_loss: 1.1735 - val_accuracy: 0.4970\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.50220\n",
      "Epoch 53/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1140 - accuracy: 0.5255 - val_loss: 1.1551 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.50220\n",
      "Epoch 54/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1112 - accuracy: 0.5243 - val_loss: 1.1495 - val_accuracy: 0.5076\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.50220 to 0.50760, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 55/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1087 - accuracy: 0.5263 - val_loss: 1.1643 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.50760\n",
      "Epoch 56/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1081 - accuracy: 0.5300 - val_loss: 1.1550 - val_accuracy: 0.5068\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.50760\n",
      "Epoch 57/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1045 - accuracy: 0.5305 - val_loss: 1.1654 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.50760\n",
      "Epoch 58/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1018 - accuracy: 0.5305 - val_loss: 1.1540 - val_accuracy: 0.5056\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.50760\n",
      "Epoch 59/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1022 - accuracy: 0.5309 - val_loss: 1.1515 - val_accuracy: 0.5052\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.50760\n",
      "Epoch 60/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.1019 - accuracy: 0.5305 - val_loss: 1.1782 - val_accuracy: 0.4936\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.50760\n",
      "Epoch 61/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0967 - accuracy: 0.5307 - val_loss: 1.1467 - val_accuracy: 0.5022\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.50760\n",
      "Epoch 62/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0881 - accuracy: 0.5354 - val_loss: 1.1548 - val_accuracy: 0.5018\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.50760\n",
      "Epoch 63/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0917 - accuracy: 0.5364 - val_loss: 1.1463 - val_accuracy: 0.5064\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.50760\n",
      "Epoch 64/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0951 - accuracy: 0.5295 - val_loss: 1.1602 - val_accuracy: 0.5026\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.50760\n",
      "Epoch 65/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0919 - accuracy: 0.5352 - val_loss: 1.1601 - val_accuracy: 0.5008\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.50760\n",
      "Epoch 66/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0992 - accuracy: 0.5316 - val_loss: 1.1382 - val_accuracy: 0.5098\n",
      "\n",
      "Epoch 00066: val_accuracy improved from 0.50760 to 0.50980, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 67/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0880 - accuracy: 0.5331 - val_loss: 1.1787 - val_accuracy: 0.4990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.50980\n",
      "Epoch 68/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0825 - accuracy: 0.5370 - val_loss: 1.1359 - val_accuracy: 0.5098\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.50980\n",
      "Epoch 69/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0869 - accuracy: 0.5349 - val_loss: 1.1567 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.50980\n",
      "Epoch 70/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0903 - accuracy: 0.5332 - val_loss: 1.1403 - val_accuracy: 0.5112\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.50980 to 0.51120, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 71/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0848 - accuracy: 0.5367 - val_loss: 1.1379 - val_accuracy: 0.5118\n",
      "\n",
      "Epoch 00071: val_accuracy improved from 0.51120 to 0.51180, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 72/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0777 - accuracy: 0.5426 - val_loss: 1.1476 - val_accuracy: 0.5060\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.51180\n",
      "Epoch 73/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0777 - accuracy: 0.5386 - val_loss: 1.1394 - val_accuracy: 0.5094\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.51180\n",
      "Epoch 74/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0733 - accuracy: 0.5429 - val_loss: 1.1375 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.51180\n",
      "Epoch 75/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0824 - accuracy: 0.5357 - val_loss: 1.1606 - val_accuracy: 0.5018\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.51180\n",
      "Epoch 76/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0747 - accuracy: 0.5448 - val_loss: 1.1357 - val_accuracy: 0.5110\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.51180\n",
      "Epoch 77/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0681 - accuracy: 0.5465 - val_loss: 1.1449 - val_accuracy: 0.5096\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.51180\n",
      "Epoch 78/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0707 - accuracy: 0.5416 - val_loss: 1.1282 - val_accuracy: 0.5184\n",
      "\n",
      "Epoch 00078: val_accuracy improved from 0.51180 to 0.51840, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 79/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0630 - accuracy: 0.5484 - val_loss: 1.1502 - val_accuracy: 0.5078\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.51840\n",
      "Epoch 80/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0681 - accuracy: 0.5421 - val_loss: 1.1369 - val_accuracy: 0.5162\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.51840\n",
      "Epoch 81/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0666 - accuracy: 0.5447 - val_loss: 1.1221 - val_accuracy: 0.5160\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.51840\n",
      "Epoch 82/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0668 - accuracy: 0.5479 - val_loss: 1.1278 - val_accuracy: 0.5110\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.51840\n",
      "Epoch 83/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0665 - accuracy: 0.5494 - val_loss: 1.1328 - val_accuracy: 0.5082\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.51840\n",
      "Epoch 84/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0569 - accuracy: 0.5504 - val_loss: 1.1421 - val_accuracy: 0.5058\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.51840\n",
      "Epoch 85/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0604 - accuracy: 0.5505 - val_loss: 1.1256 - val_accuracy: 0.5098\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.51840\n",
      "Epoch 86/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0615 - accuracy: 0.5486 - val_loss: 1.1384 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.51840\n",
      "Epoch 87/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0603 - accuracy: 0.5515 - val_loss: 1.1433 - val_accuracy: 0.5072\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.51840\n",
      "Epoch 88/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0551 - accuracy: 0.5548 - val_loss: 1.1429 - val_accuracy: 0.5072\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.51840\n",
      "Epoch 89/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0539 - accuracy: 0.5553 - val_loss: 1.1664 - val_accuracy: 0.5050\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.51840\n",
      "Epoch 90/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0526 - accuracy: 0.5541 - val_loss: 1.1476 - val_accuracy: 0.5042\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.51840\n",
      "Epoch 91/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0503 - accuracy: 0.5532 - val_loss: 1.1484 - val_accuracy: 0.5080\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.51840\n",
      "Epoch 92/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0464 - accuracy: 0.5560 - val_loss: 1.1492 - val_accuracy: 0.5050\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.51840\n",
      "Epoch 93/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0487 - accuracy: 0.5546 - val_loss: 1.1257 - val_accuracy: 0.5176\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.51840\n",
      "Epoch 94/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0471 - accuracy: 0.5539 - val_loss: 1.1153 - val_accuracy: 0.5194\n",
      "\n",
      "Epoch 00094: val_accuracy improved from 0.51840 to 0.51940, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 95/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0437 - accuracy: 0.5561 - val_loss: 1.1416 - val_accuracy: 0.5126\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.51940\n",
      "Epoch 96/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0371 - accuracy: 0.5608 - val_loss: 1.1423 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.51940\n",
      "Epoch 97/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0370 - accuracy: 0.5618 - val_loss: 1.1866 - val_accuracy: 0.4974\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.51940\n",
      "Epoch 98/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0330 - accuracy: 0.5593 - val_loss: 1.1239 - val_accuracy: 0.5166\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.51940\n",
      "Epoch 99/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0345 - accuracy: 0.5603 - val_loss: 1.1459 - val_accuracy: 0.5156\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.51940\n",
      "Epoch 100/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0274 - accuracy: 0.5644 - val_loss: 1.1168 - val_accuracy: 0.5252\n",
      "\n",
      "Epoch 00100: val_accuracy improved from 0.51940 to 0.52520, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 101/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0387 - accuracy: 0.5587 - val_loss: 1.1325 - val_accuracy: 0.5122\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.52520\n",
      "Epoch 102/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0365 - accuracy: 0.5594 - val_loss: 1.1269 - val_accuracy: 0.5158\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.52520\n",
      "Epoch 103/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0328 - accuracy: 0.5621 - val_loss: 1.1250 - val_accuracy: 0.5194\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.52520\n",
      "Epoch 104/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0259 - accuracy: 0.5654 - val_loss: 1.1223 - val_accuracy: 0.5170\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.52520\n",
      "Epoch 105/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0280 - accuracy: 0.5643 - val_loss: 1.1434 - val_accuracy: 0.5144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.52520\n",
      "Epoch 106/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0212 - accuracy: 0.5664 - val_loss: 1.1126 - val_accuracy: 0.5268\n",
      "\n",
      "Epoch 00106: val_accuracy improved from 0.52520 to 0.52680, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 107/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0250 - accuracy: 0.5673 - val_loss: 1.1171 - val_accuracy: 0.5236\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.52680\n",
      "Epoch 108/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0271 - accuracy: 0.5671 - val_loss: 1.1131 - val_accuracy: 0.5252\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.52680\n",
      "Epoch 109/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0236 - accuracy: 0.5673 - val_loss: 1.1110 - val_accuracy: 0.5264\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.52680\n",
      "Epoch 110/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0166 - accuracy: 0.5678 - val_loss: 1.1203 - val_accuracy: 0.5184\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.52680\n",
      "Epoch 111/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0178 - accuracy: 0.5699 - val_loss: 1.1344 - val_accuracy: 0.5218\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.52680\n",
      "Epoch 112/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0185 - accuracy: 0.5661 - val_loss: 1.1320 - val_accuracy: 0.5140\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.52680\n",
      "Epoch 113/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0125 - accuracy: 0.5729 - val_loss: 1.1368 - val_accuracy: 0.5172\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.52680\n",
      "Epoch 114/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0134 - accuracy: 0.5705 - val_loss: 1.1761 - val_accuracy: 0.5076\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.52680\n",
      "Epoch 115/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0118 - accuracy: 0.5739 - val_loss: 1.1536 - val_accuracy: 0.5208\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.52680\n",
      "Epoch 116/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0062 - accuracy: 0.5740 - val_loss: 1.1075 - val_accuracy: 0.5304\n",
      "\n",
      "Epoch 00116: val_accuracy improved from 0.52680 to 0.53040, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 117/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0059 - accuracy: 0.5743 - val_loss: 1.1565 - val_accuracy: 0.5086\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.53040\n",
      "Epoch 118/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0076 - accuracy: 0.5711 - val_loss: 1.1120 - val_accuracy: 0.5292\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.53040\n",
      "Epoch 119/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0052 - accuracy: 0.5775 - val_loss: 1.1402 - val_accuracy: 0.5226\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.53040\n",
      "Epoch 120/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 1.0011 - accuracy: 0.5802 - val_loss: 1.1346 - val_accuracy: 0.5336\n",
      "\n",
      "Epoch 00120: val_accuracy improved from 0.53040 to 0.53360, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 121/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9972 - accuracy: 0.5746 - val_loss: 1.1381 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.53360\n",
      "Epoch 122/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9964 - accuracy: 0.5779 - val_loss: 1.1699 - val_accuracy: 0.5054\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.53360\n",
      "Epoch 123/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9976 - accuracy: 0.5788 - val_loss: 1.1044 - val_accuracy: 0.5316\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.53360\n",
      "Epoch 124/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9916 - accuracy: 0.5851 - val_loss: 1.1091 - val_accuracy: 0.5300\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.53360\n",
      "Epoch 125/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9930 - accuracy: 0.5808 - val_loss: 1.1725 - val_accuracy: 0.5124\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.53360\n",
      "Epoch 126/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9847 - accuracy: 0.5853 - val_loss: 1.1078 - val_accuracy: 0.5336\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.53360\n",
      "Epoch 127/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9880 - accuracy: 0.5790 - val_loss: 1.1084 - val_accuracy: 0.5346\n",
      "\n",
      "Epoch 00127: val_accuracy improved from 0.53360 to 0.53460, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 128/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9918 - accuracy: 0.5805 - val_loss: 1.1268 - val_accuracy: 0.5254\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.53460\n",
      "Epoch 129/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9832 - accuracy: 0.5837 - val_loss: 1.0992 - val_accuracy: 0.5452\n",
      "\n",
      "Epoch 00129: val_accuracy improved from 0.53460 to 0.54520, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 130/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9860 - accuracy: 0.5835 - val_loss: 1.0987 - val_accuracy: 0.5334\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.54520\n",
      "Epoch 131/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9787 - accuracy: 0.5872 - val_loss: 1.1290 - val_accuracy: 0.5320\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.54520\n",
      "Epoch 132/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9798 - accuracy: 0.5873 - val_loss: 1.1109 - val_accuracy: 0.5322\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.54520\n",
      "Epoch 133/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9887 - accuracy: 0.5825 - val_loss: 1.1359 - val_accuracy: 0.5240\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.54520\n",
      "Epoch 134/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9842 - accuracy: 0.5826 - val_loss: 1.1354 - val_accuracy: 0.5206\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.54520\n",
      "Epoch 135/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9667 - accuracy: 0.5926 - val_loss: 1.1062 - val_accuracy: 0.5396\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.54520\n",
      "Epoch 136/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9759 - accuracy: 0.5917 - val_loss: 1.1239 - val_accuracy: 0.5352\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.54520\n",
      "Epoch 137/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9755 - accuracy: 0.5884 - val_loss: 1.0978 - val_accuracy: 0.5358\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.54520\n",
      "Epoch 138/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9727 - accuracy: 0.5907 - val_loss: 1.1057 - val_accuracy: 0.5408\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.54520\n",
      "Epoch 139/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9726 - accuracy: 0.5891 - val_loss: 1.1054 - val_accuracy: 0.5410\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.54520\n",
      "Epoch 140/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9694 - accuracy: 0.5930 - val_loss: 1.1227 - val_accuracy: 0.5354\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.54520\n",
      "Epoch 141/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9703 - accuracy: 0.5964 - val_loss: 1.1203 - val_accuracy: 0.5338\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.54520\n",
      "Epoch 142/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9668 - accuracy: 0.5892 - val_loss: 1.1358 - val_accuracy: 0.5216\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.54520\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9643 - accuracy: 0.5950 - val_loss: 1.0952 - val_accuracy: 0.5382\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.54520\n",
      "Epoch 144/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9642 - accuracy: 0.5961 - val_loss: 1.1083 - val_accuracy: 0.5326\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.54520\n",
      "Epoch 145/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9668 - accuracy: 0.5930 - val_loss: 1.1364 - val_accuracy: 0.5292\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.54520\n",
      "Epoch 146/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9642 - accuracy: 0.5946 - val_loss: 1.0949 - val_accuracy: 0.5460\n",
      "\n",
      "Epoch 00146: val_accuracy improved from 0.54520 to 0.54600, saving model to /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "Epoch 147/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9630 - accuracy: 0.6000 - val_loss: 1.0996 - val_accuracy: 0.5438\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.54600\n",
      "Epoch 148/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9551 - accuracy: 0.5984 - val_loss: 1.1217 - val_accuracy: 0.5340\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.54600\n",
      "Epoch 149/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9585 - accuracy: 0.5956 - val_loss: 1.1447 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.54600\n",
      "Epoch 150/150\n",
      "450/450 [==============================] - 12s 26ms/step - loss: 0.9605 - accuracy: 0.5984 - val_loss: 1.1040 - val_accuracy: 0.5406\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.54600\n",
      "[LOG] -- model save to path: /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/model/best_model.h5\n",
      "RUNTIME:  1900.9726264476776\n",
      "TIME PER EPOCH 12.673150842984517\n"
     ]
    }
   ],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/em/xmega/X1_K1_150k_L11.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_EM_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1_EM/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1_EM/fpgm/h512/ -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1_EM/fpgm/custum/N512/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc97b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/fpgm/h128 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/fpgm/custum/N128/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7add53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/fpgm/h256 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/fpgm/custum/N256/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94322ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/fpgm/h512 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/fpgm/custum/N512/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/fpgm/fpgm_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/fpgm/h1024 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/fpgm/custum/N1024/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9be3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h32 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N32/1-pr.csv\n",
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h64 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N64/1-pr.csv\n",
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h128 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N128/1-pr.csv\n",
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h256 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N256/1-pr.csv\n",
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h512 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N512/1-pr.csv\n",
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h1024 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N1024/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff50d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run \"cnn/new_train.py\" -aw 1800_2800 -i /home/mabon/Tiny_power/datasets/power/xmega_unmasked/X1_K1_200k.npz -m /home/mabon/Tiny_power/models/original/HW/xmega/X1_50k/ -rp /home/mabon/Tiny_power/Score/Xmega/HW/X1/l2/l2_idx.csv -o /home/mabon/Tiny_power/models/custom_prunded/HW/xmega/X1/l2/h128 -v -e 150 -tb 2 -lm hw_model -tn 50000 -CP 'True' -CPP  /home/mabon/Tiny_power/Score/CUSTOM/Xmega/HW/X1/l2/custum/N128/1-pr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c382e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
